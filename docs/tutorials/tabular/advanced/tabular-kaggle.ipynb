{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0fa7eb3d",
      "metadata": {
        "id": "0fa7eb3d"
      },
      "source": [
        "# How to use AutoGluon for Kaggle competitions\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "This tutorial will teach you how to use AutoGluon to become a serious Kaggle competitor without writing lots of code.\n",
        "We first outline the general steps to use AutoGluon in Kaggle contests. Here, we assume the competition involves tabular data which are stored in one (or more) CSV files.\n",
        "\n",
        "1) Run Bash command: pip install kaggle\n",
        "\n",
        "2) Navigate to: https://www.kaggle.com/account and create an account (if necessary).\n",
        "Then , click on \"Create New API Token\" and move downloaded file to this location on your machine: `~/.kaggle/kaggle.json`. For troubleshooting, see [Kaggle API instructions](https://www.kaggle.com/docs/api).\n",
        "\n",
        "3) To download data programmatically: Execute this Bash command in your terminal:\n",
        "\n",
        "`kaggle competitions download -c [COMPETITION]`\n",
        "\n",
        "Here, [COMPETITION] should be replaced by the name of the competition you wish to enter.\n",
        "Alternatively, you can download data manually: Just navigate to website of the Kaggle competition you wish to enter, click \"Download All\", and accept the competition's terms.\n",
        "\n",
        "4) If the competition's training data is comprised of multiple CSV files, use [pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to properly merge/join them into a single data table where rows = training examples, columns = features.\n",
        "\n",
        "5) Run autogluon `fit()` on the resulting data table.\n",
        "\n",
        "6) Load the test dataset from competition (again making the necessary merges/joins to ensure it is in the exact same format as the training data table), and then call autogluon `predict()`.  Subsequently use [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to load the competition's `sample_submission.csv` file into a DataFrame, put the AutoGluon predictions in the right column of this DataFrame, and finally save it as a CSV file via [pandas.to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html). If the competition does not offer a sample submission file, you will need to create the submission file yourself by appropriately reformatting AutoGluon's test predictions.\n",
        "\n",
        "7) Submit your predictions via Bash command:\n",
        "\n",
        "`kaggle competitions submit -c [COMPETITION] -f [FILE] -m [\"MESSAGE\"]`\n",
        "\n",
        "Here, [COMPETITION] again is the competition's name, [FILE] is the name of the CSV file you created with your predictions, and [\"MESSAGE\"] is a string message you want to record with this submitted entry. Alternatively, you can  manually upload your file of predictions on the competition website.\n",
        "\n",
        "8) Finally, navigate to competition leaderboard website to see how well your submission performed!\n",
        "It may take time for your submission to appear.\n",
        "\n",
        "\n",
        "\n",
        "Below, we demonstrate how to do steps (4)-(6) in Python for a specific Kaggle competition: [ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/).\n",
        "This means you'll need to run the above steps with `[COMPETITION]` replaced by `ieee-fraud-detection` in each command.  Here, we assume you've already completed steps (1)-(3) and the data CSV files are available on your computer. To begin step (4), we first load the competition's training data into Python:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle and download the competition data\n",
        "!pip install kaggle\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "\n",
        "# Unzip the downloaded files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.endswith('.zip'):\n",
        "        zip_ref = zipfile.ZipFile(file, 'r')\n",
        "        zip_ref.extractall()\n",
        "        zip_ref.close()\n",
        "        print(f\"Extracted {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx_VW9nCrN3e",
        "outputId": "8ca3eef8-c83e-4097-a28e-dde12e27ee14"
      },
      "id": "zx_VW9nCrN3e",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 4, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6057bf4",
      "metadata": {
        "id": "a6057bf4"
      },
      "source": [
        "```\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = '~/IEEEfraud/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuC1FlJwZ2R-",
        "outputId": "107b8faa-8013-41ff-80ef-a7aca0976658"
      },
      "id": "yuC1FlJwZ2R-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.4.0 (from autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting autogluon.multimodal==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.4.0 (from autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.timeseries-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading boto3-1.40.52-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (0.2.7)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (18.1.0)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (11.3.0)\n",
            "Collecting torch<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting lightning<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.10.1)\n",
            "Requirement already satisfied: fsspec<=2025.3 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2025.3.0)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.23.0,>=0.16.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.3.0)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.9.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.19.0)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.8.4)\n",
            "Collecting loguru (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (4.6.0)\n",
            "Collecting einx (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: xgboost<3.1,>=2.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.0.5)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.8.7)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.35.3)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.5.2)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.11.3)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (0.6.2)\n",
            "Collecting botocore<1.41.0,>=1.40.52 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading botocore-1.40.52-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.70.16)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.8.12)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (2.5.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (3.1.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (3.13.0)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.11.10)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.27.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (2024.11.6)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon) (4.9.3)\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.20.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.29.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.8.0)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.75.1)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (7.3.1)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading virtualenv-20.35.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.10.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2025.10.4)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.14.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.1.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.80)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.5.4.2)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.11.1.6)\n",
            "Collecting triton==3.3.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx->autogluon.tabular[all]==1.4.0->autogluon) (2.4.6)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.4.0->autogluon) (1.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (1.22.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.1.5)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.17.3)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.25.2)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.16.5)\n",
            "Collecting colorlog (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.0.43)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (8.5.0)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.22.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.38.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.2.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.8)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging>=20.0 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.4.0-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.4.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.52-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.40.52-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.3-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.7-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=2f05d7f5190d1672eed0c6cc7d0bd2cbff4e614bcdfb9682d6ef92e6650c8aaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/65/79/33dee66cba26e8204801916dfee7481bccfd22905ebb841fe5\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=1b2b72d845a37b79bf25da078a2069ed49b837c8881964f1a7f0d50fc51a3fb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built nvidia-ml-py3 seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, nvidia-cusparselt-cu12, distlib, colorful, appdirs, virtualenv, triton, tensorboardX, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, nvidia-nccl-cu12, nvidia-cudnn-cu12, loguru, lightning-utilities, jmespath, fs, coreforecast, colorlog, colorama, window-ops, model-index, einx, botocore, utilsforecast, triad, torch, tokenizers, seqeval, s3transfer, optuna, opendatalab, jsonschema, gluonts, catboost, aiohttp_cors, transformers, torchvision, torchmetrics, ray, pytorch-metric-learning, openmim, opencensus, nlpaug, mlforecast, boto3, adagio, timm, pytorch-lightning, fugue, evaluate, autogluon.common, statsforecast, lightning, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.0\n",
            "    Uninstalling transformers-4.57.0:\n",
            "      Successfully uninstalled transformers-4.57.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.20\n",
            "    Uninstalling timm-1.0.20:\n",
            "      Successfully uninstalled timm-1.0.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 appdirs-1.4.4 autogluon-1.4.0 autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.multimodal-1.4.0 autogluon.tabular-1.4.0 autogluon.timeseries-1.4.0 boto3-1.40.52 botocore-1.40.52 catboost-1.2.8 colorama-0.4.6 colorful-0.5.7 colorlog-6.9.0 coreforecast-0.0.16 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 fs-2.4.16 fugue-0.9.1 gluonts-0.16.2 jmespath-1.0.1 jsonschema-4.23.0 lightning-2.5.5 lightning-utilities-0.15.2 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 nlpaug-1.1.11 nvidia-cudnn-cu12-9.5.1.17 nvidia-cusparselt-cu12-0.6.3 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.26.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.5.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.1 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.5 pytorch-metric-learning-2.8.1 ray-2.44.1 s3transfer-0.14.0 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.4 timm-1.0.3 tokenizers-0.21.4 torch-2.7.1 torchmetrics-1.7.4 torchvision-0.22.1 transformers-4.49.0 triad-0.9.8 triton-3.3.1 utilsforecast-0.2.11 virtualenv-20.35.3 window-ops-0.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = '/content/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "zhKO64pBZx8A"
      },
      "id": "zhKO64pBZx8A",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1b046735",
      "metadata": {
        "id": "1b046735"
      },
      "source": [
        "Since the training data for this competition is comprised of multiple CSV files, we just first join them into a single large table (with rows = examples, columns = features) before applying AutoGluon:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ddbf2bd",
      "metadata": {
        "id": "9ddbf2bd"
      },
      "source": [
        "```\n",
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "NYMGzx80aBa2"
      },
      "id": "NYMGzx80aBa2",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fgOzsIVaAsi"
      },
      "id": "9fgOzsIVaAsi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7de8c287",
      "metadata": {
        "id": "7de8c287"
      },
      "source": [
        "Note that a left-join on the `TransactionID` key happened to be most appropriate for this Kaggle competition, but for others involving multiple training data files, you will likely need to use a different join strategy (always consider this very carefully). Now that all our training data resides within a single table, we can apply AutoGluon. Below, we specify the `presets` argument to maximize AutoGluon's predictive accuracy which usually requires that you run `fit()` with longer time limits (3600s below should likely be increased in your run):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaad348b",
      "metadata": {
        "id": "aaad348b"
      },
      "source": [
        "```\n",
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='best_quality', time_limit=3600\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='best_quality', time_limit=3600, dynamic_stacking=False\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPiJOdowaDZ2",
        "outputId": "620644ea-24c9-4e94-88db-c5afb2029fc3"
      },
      "id": "vPiJOdowaDZ2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          8\n",
            "GPU Count:          0\n",
            "Memory Avail:       47.43 GB / 50.99 GB (93.0%)\n",
            "Disk Space Avail:   179.54 GB / 225.83 GB (79.5%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True, 'num_bag_sets': 1}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"/content/AutoGluonModels\"\n",
            "Train Data Rows:    150046\n",
            "Train Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    48692.57 MB\n",
            "\tTrain Data (Original)  Memory Usage: 636.14 MB (1.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\t\t('object', [])    :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.8s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\t\t('object', [])    :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\t\t('object', [])    :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\t0.2s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.0s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])     : 398 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\t0.9s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t8 duplicate columns removed: ['V28', 'V305', 'V113', 'V119', 'V147', 'V154', 'V163', 'V239']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])     : 390 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])     : 390 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t\t\t4.9s = Fit runtime\n",
            "\t\t\t425 features in original data used to generate 425 features in processed data.\n",
            "\tUnused Original Features (Count: 8): ['V28', 'V113', 'V119', 'V147', 'V154', 'V163', 'V239', 'V305']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 8 | ['V28', 'V113', 'V119', 'V147', 'V154', ...]\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 390 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('int8', 'int')          :   1 | ['V107']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])     : 390 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('int', ['bool']) :   1 | ['V107']\n",
            "\t10.4s = Fit runtime\n",
            "\t425 features in original data used to generate 425 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 454.63 MB (0.9% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 11.32s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "}\n",
            "Saving /content/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 588.68s of the 588.54s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.32%)\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\t0.9576\t = Validation score   (roc_auc)\n",
            "\t387.98s\t = Training   runtime\n",
            "\t43.74s\t = Validation runtime\n",
            "\t428.8\t = Inference  throughput (rows/s | 18756 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 183.69s of the 183.56s of remaining time.\n",
            "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=9.30%)\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "\t0.957\t = Validation score   (roc_auc)\n",
            "\t175.18s\t = Training   runtime\n",
            "\t16.02s\t = Validation runtime\n",
            "\t1171.1\t = Inference  throughput (rows/s | 18756 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -0.20s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 13\n",
            "Ensemble weights: \n",
            "[0.69230769 0.30769231]\n",
            "\t0.45s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.692, 'LightGBM_BAG_L1': 0.308}\n",
            "\t0.9593\t = Validation score   (roc_auc)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t313.9\t = Inference  throughput (rows/s | 18756 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 605.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 313.9 rows/s (18756 batch size)\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Saving /content/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels\")\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L2   0.959286     roc_auc      59.777736  564.388771                0.024294           1.233692            2       True          3\n",
            "1    LightGBMXT_BAG_L1   0.957623     roc_auc      43.737784  387.979524               43.737784         387.979524            1       True          1\n",
            "2      LightGBM_BAG_L1   0.956969     roc_auc      16.015657  175.175555               16.015657         175.175555            1       True          2\n",
            "Number of models trained: 3\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])     : 390 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])       :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "('int', ['bool']) :   1 | ['V107']\n",
            "Plot summary of models saved to file: /content/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "010f5fef",
      "metadata": {
        "id": "010f5fef"
      },
      "source": [
        "Now, we use the trained AutoGluon Predictor to make predictions on the competition's test data. It is imperative that multiple test data files are joined together in the exact same manner as the training data. Because this competition is evaluated based on the AUC (Area under the ROC curve) metric, we ask AutoGluon for predicted class-probabilities rather than class predictions. In general, when to use `predict` vs `predict_proba` will depend on the particular competition."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75bc10a9",
      "metadata": {
        "id": "75bc10a9"
      },
      "source": [
        "```\n",
        "test_identity = pd.read_csv(directory+'test_identity.csv')\n",
        "test_transaction = pd.read_csv(directory+'test_transaction.csv')\n",
        "test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n",
        "\n",
        "y_predproba = predictor.predict_proba(test_data)\n",
        "y_predproba.head(5)  # some example predicted fraud-probabilities\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_identity = pd.read_csv(directory+'test_identity.csv')\n",
        "test_transaction = pd.read_csv(directory+'test_transaction.csv')\n",
        "test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n",
        "\n",
        "y_predproba = predictor.predict_proba(test_data)\n",
        "y_predproba.head(5)  # some example predicted fraud-probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affzvIt5aFjD",
        "outputId": "0c4e4c08-66ac-4137-950c-6804f6f02eb2"
      },
      "id": "affzvIt5aFjD",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in train_data:\n",
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n",
            "\n",
            "Columns in test_data:\n",
            "Index(['TransactionID', 'TransactionDT', 'TransactionAmt', 'ProductCD',\n",
            "       'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
            "       ...\n",
            "       'id-31', 'id-32', 'id-33', 'id-34', 'id-35', 'id-36', 'id-37', 'id-38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd379db",
      "metadata": {
        "id": "2cd379db"
      },
      "source": [
        "When submitting predicted probabilities for classification competitions, it is imperative these correspond to the same class expected by Kaggle. For binary classification tasks, you can see which class AutoGluon's predicted probabilities correspond to via:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b65205",
      "metadata": {
        "id": "79b65205"
      },
      "source": [
        "```\n",
        "predictor.positive_class\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb10vhL4aIKe",
        "outputId": "e96eecf6-0cd2-4dde-9687-af070fe0d7cb"
      },
      "id": "Fb10vhL4aIKe",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb03739b",
      "metadata": {
        "id": "bb03739b"
      },
      "source": [
        "For multiclass classification tasks, you can see which classes AutoGluon's predicted probabilities correspond to via:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9020a4f9",
      "metadata": {
        "id": "9020a4f9"
      },
      "source": [
        "```\n",
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PE0p0_2aJ0U",
        "outputId": "81edbece-79e9-4979-a630-38024802fa7f"
      },
      "id": "9PE0p0_2aJ0U",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb84c3e",
      "metadata": {
        "id": "8cb84c3e"
      },
      "source": [
        "Now, let's get prediction probabilities for the entire test data, while only getting the positive class predictions by specifying:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e82e4c9",
      "metadata": {
        "id": "3e82e4c9"
      },
      "source": [
        "```\n",
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "sQOIQCZzaLW0",
        "outputId": "52bb92b3-8a88-464f-b33a-eedf349b56b9"
      },
      "id": "sQOIQCZzaLW0",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"38 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 38 missing columns: ['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'] | 433 available columns: ['TransactionID', 'TransactionDT', 'TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id-01', 'id-02', 'id-03', 'id-04', 'id-05', 'id-06', 'id-07', 'id-08', 'id-09', 'id-10', 'id-11', 'id-12', 'id-13', 'id-14', 'id-15', 'id-16', 'id-17', 'id-18', 'id-19', 'id-20', 'id-21', 'id-22', 'id-23', 'id-24', 'id-25', 'id-26', 'id-27', 'id-28', 'id-29', 'id-30', 'id-31', 'id-32', 'id-33', 'id-34', 'id-35', 'id-36', 'id-37', 'id-38', 'DeviceType', 'DeviceInfo']\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/features/generators/abstract.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;31m# therefore, try avoid copying by checking the expected features first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'] not in index\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2778821945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, model, as_pandas, as_multiclass, transform_features)\u001b[0m\n\u001b[1;32m   2487\u001b[0m             )\n\u001b[1;32m   2488\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_pandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_multiclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_from_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         y_pred_proba = self._post_process_predict_proba(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mtransform_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_generator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_generators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/features/generators/abstract.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mmissing_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0;34mf\"{len(missing_cols)} required columns are missing from the provided dataset to transform using {self.__class__.__name__}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;34mf\"{len(missing_cols)} missing columns: {missing_cols} | \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"38 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 38 missing columns: ['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'] | 433 available columns: ['TransactionID', 'TransactionDT', 'TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80'..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f26a317",
      "metadata": {
        "id": "9f26a317"
      },
      "source": [
        "Now that we have made a prediction for each row in the test dataset, we can submit these predictions to Kaggle. Most Kaggle competitions provide a sample submission file, in which you can simply overwrite the sample predictions with your own as we do below:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "pk3sSScLaM0m"
      },
      "id": "pk3sSScLaM0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ef9ae74e",
      "metadata": {
        "id": "ef9ae74e"
      },
      "source": [
        "```\n",
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd99892",
      "metadata": {
        "id": "2fd99892"
      },
      "source": [
        "We have now completed steps (4)-(6) from the top of this tutorial. To submit your predictions to Kaggle, you can run the following command in your terminal (from the appropriate directory):\n",
        "\n",
        "`kaggle competitions submit -c ieee-fraud-detection -f sample_submission.csv -m \"my first submission\"`\n",
        "\n",
        "You can now play with different `fit()` arguments and feature-engineering techniques to try and maximize the rank of your submissions in the Kaggle Leaderboard!\n",
        "\n",
        "\n",
        "**Tips to maximize predictive performance:**\n",
        "\n",
        "   - Be sure to specify the appropriate evaluation metric if one is specified on the competition website! If you are unsure which metric is best, then simply do not specify this argument when invoking `fit()`; AutoGluon should still produce high-quality models by automatically inferring which metric to use.\n",
        "\n",
        "   - If the training examples are time-based and the competition test examples come from future data, we recommend you reserve the most recently-collected training examples as a separate validation dataset passed to `fit()`. Otherwise, you do not need to specify a validation set yourself and AutoGluon will automatically partition the competition training data into its own training/validation sets.\n",
        "\n",
        "   - Beyond simply specifying `presets = 'best_quality'`, you may play with more advanced `fit()` arguments such as: `num_bag_folds`, `num_stack_levels`, `num_bag_sets`, `hyperparameter_tune_kwargs`, `hyperparameters`, `refit_full`. However we recommend spending most of your time on feature-engineering and just specify `presets = 'best_quality'` inside the call to `fit()`.\n",
        "\n",
        "\n",
        "**Troubleshooting:**\n",
        "\n",
        "- Check that you have the right user-permissions on your computer to access the data files downloaded from Kaggle.\n",
        "\n",
        "- For issues downloading Kaggle data or submitting predictions, check your Kaggle account setup and the [Kaggle FAQ](https://www.kaggle.com/general/14438)."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}