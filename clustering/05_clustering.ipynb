{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdg/rldT/bY29xRgHKGkri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatamadavi/data_mining/blob/main/clustering/05_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BxtMbVn0rxS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part e) Anomaly Detection using PyOD\n",
        "\n",
        "This section demonstrates anomaly detection using the Python Outlier Detection (PyOD) library on a multivariate dataset."
      ],
      "metadata": {
        "id": "HDJ4ODC94HDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyOD library\n",
        "!pip install pyod"
      ],
      "metadata": {
        "id": "3m7HxCWs4Xnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# PyOD imports\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.lof import LOF\n",
        "from pyod.utils.data import generate_data\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "oAZbis_F4fUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic multivariate data with outliers\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate normal data points\n",
        "n_samples = 300\n",
        "n_outliers = 30\n",
        "n_features = 2\n",
        "\n",
        "# Generate inliers (normal data)\n",
        "X_inliers = np.random.randn(n_samples, n_features) * 2\n",
        "\n",
        "# Generate outliers (anomalies)\n",
        "X_outliers = np.random.uniform(low=-8, high=8, size=(n_outliers, n_features))\n",
        "\n",
        "# Combine inliers and outliers\n",
        "X = np.vstack([X_inliers, X_outliers])\n",
        "\n",
        "# Create ground truth labels (0 = normal, 1 = outlier)\n",
        "y_true = np.hstack([np.zeros(n_samples), np.ones(n_outliers)])\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of normal points: {n_samples}\")\n",
        "print(f\"Number of outliers: {n_outliers}\")\n",
        "print(f\"Contamination rate: {n_outliers / (n_samples + n_outliers):.2%}\")"
      ],
      "metadata": {
        "id": "i7iDOw2M4k_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data before anomaly detection\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X[y_true==0, 0], X[y_true==0, 1],\n",
        "            c='blue', alpha=0.6, s=50, label='Normal Points')\n",
        "plt.scatter(X[y_true==1, 0], X[y_true==1, 1],\n",
        "            c='red', alpha=0.8, s=100, marker='x', label='True Anomalies')\n",
        "plt.xlabel('Feature 1', fontsize=12)\n",
        "plt.ylabel('Feature 2', fontsize=12)\n",
        "plt.title('Original Data with True Anomalies', fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4H3LCnbt4s6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train multiple PyOD anomaly detection models\n",
        "contamination = n_outliers / (n_samples + n_outliers)  # Expected proportion of outliers\n",
        "\n",
        "print(\"Training anomaly detection models...\")\n",
        "print(f\"Contamination rate used: {contamination:.2%}\\n\")\n",
        "\n",
        "# 1. K-Nearest Neighbors (KNN) Detector\n",
        "print(\"1. Training KNN Detector...\")\n",
        "knn_clf = KNN(contamination=contamination, n_neighbors=5)\n",
        "knn_clf.fit(X)\n",
        "y_pred_knn = knn_clf.predict(X)  # 0 for normal, 1 for anomaly\n",
        "knn_scores = knn_clf.decision_scores_  # Outlier scores\n",
        "print(\"   KNN training complete!\")\n",
        "\n",
        "# 2. Isolation Forest\n",
        "print(\"2. Training Isolation Forest...\")\n",
        "iforest_clf = IForest(contamination=contamination, random_state=42)\n",
        "iforest_clf.fit(X)\n",
        "y_pred_iforest = iforest_clf.predict(X)\n",
        "iforest_scores = iforest_clf.decision_scores_\n",
        "print(\"   Isolation Forest training complete!\")\n",
        "\n",
        "# 3. Local Outlier Factor (LOF)\n",
        "print(\"3. Training LOF Detector...\")\n",
        "lof_clf = LOF(contamination=contamination, n_neighbors=20)\n",
        "lof_clf.fit(X)\n",
        "y_pred_lof = lof_clf.predict(X)\n",
        "lof_scores = lof_clf.decision_scores_\n",
        "print(\"   LOF training complete!\")\n",
        "\n",
        "print(\"\\nAll models trained successfully!\")"
      ],
      "metadata": {
        "id": "p__w7Zy841pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANOMALY DETECTION PERFORMANCE EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "models = {\n",
        "    'KNN': y_pred_knn,\n",
        "    'Isolation Forest': y_pred_iforest,\n",
        "    'LOF': y_pred_lof\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, y_pred in models.items():\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1\n",
        "    })\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nSummary Table:\")\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "vuLBzMCR4-jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize anomaly detection results for all models\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Original Data with True Anomalies\n",
        "ax1 = axes[0, 0]\n",
        "ax1.scatter(X[y_true==0, 0], X[y_true==0, 1],\n",
        "            c='blue', alpha=0.6, s=50, label='Normal Points')\n",
        "ax1.scatter(X[y_true==1, 0], X[y_true==1, 1],\n",
        "            c='red', alpha=0.8, s=100, marker='x', label='True Anomalies')\n",
        "ax1.set_xlabel('Feature 1', fontsize=11)\n",
        "ax1.set_ylabel('Feature 2', fontsize=11)\n",
        "ax1.set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: KNN Detector Results\n",
        "ax2 = axes[0, 1]\n",
        "ax2.scatter(X[y_pred_knn==0, 0], X[y_pred_knn==0, 1],\n",
        "            c='blue', alpha=0.6, s=50, label='Predicted Normal')\n",
        "ax2.scatter(X[y_pred_knn==1, 0], X[y_pred_knn==1, 1],\n",
        "            c='orange', alpha=0.8, s=100, marker='s', label='Predicted Anomalies')\n",
        "ax2.set_xlabel('Feature 1', fontsize=11)\n",
        "ax2.set_ylabel('Feature 2', fontsize=11)\n",
        "ax2.set_title(f'KNN Detector (F1: {f1_score(y_true, y_pred_knn):.3f})',\n",
        "              fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Isolation Forest Results\n",
        "ax3 = axes[1, 0]\n",
        "ax3.scatter(X[y_pred_iforest==0, 0], X[y_pred_iforest==0, 1],\n",
        "            c='blue', alpha=0.6, s=50, label='Predicted Normal')\n",
        "ax3.scatter(X[y_pred_iforest==1, 0], X[y_pred_iforest==1, 1],\n",
        "            c='green', alpha=0.8, s=100, marker='^', label='Predicted Anomalies')\n",
        "ax3.set_xlabel('Feature 1', fontsize=11)\n",
        "ax3.set_ylabel('Feature 2', fontsize=11)\n",
        "ax3.set_title(f'Isolation Forest (F1: {f1_score(y_true, y_pred_iforest):.3f})',\n",
        "              fontsize=12, fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: LOF Results\n",
        "ax4 = axes[1, 1]\n",
        "ax4.scatter(X[y_pred_lof==0, 0], X[y_pred_lof==0, 1],\n",
        "            c='blue', alpha=0.6, s=50, label='Predicted Normal')\n",
        "ax4.scatter(X[y_pred_lof==1, 0], X[y_pred_lof==1, 1],\n",
        "            c='purple', alpha=0.8, s=100, marker='d', label='Predicted Anomalies')\n",
        "ax4.set_xlabel('Feature 1', fontsize=11)\n",
        "ax4.set_ylabel('Feature 2', fontsize=11)\n",
        "ax4.set_title(f'LOF Detector (F1: {f1_score(y_true, y_pred_lof):.3f})',\n",
        "              fontsize=12, fontweight='bold')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Anomaly Detection Results Comparison',\n",
        "             fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b6JyTnnA5IGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Conclusions\n",
        "\n",
        "In this demonstration, we successfully implemented anomaly detection using the **PyOD (Python Outlier Detection)** library on a multivariate dataset.\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "1. **Dataset**: Created a synthetic 2D dataset with 300 normal points and 30 outliers (~9% contamination rate)\n",
        "\n",
        "2. **Models Tested**:\n",
        "   - **K-Nearest Neighbors (KNN)**: Distance-based approach that identifies anomalies based on their distance to nearest neighbors\n",
        "   - **Isolation Forest**: Tree-based ensemble method that isolates anomalies through random partitioning\n",
        "   - **Local Outlier Factor (LOF)**: Density-based method that compares local density of points\n",
        "\n",
        "3. **Performance**: All three models demonstrated strong anomaly detection capabilities, with evaluation metrics including accuracy, precision, recall, and F1-score\n",
        "\n",
        "### Use Cases:\n",
        "PyOD is widely used in real-world applications including:\n",
        "- **Fraud Detection**: Identifying unusual transaction patterns in financial systems\n",
        "- **Network Security**: Detecting intrusions and malicious activities\n",
        "- **Manufacturing**: Quality control and defect detection\n",
        "- **Healthcare**: Identifying unusual patient conditions or medical anomalies\n",
        "- **Time Series Monitoring**: Detecting anomalies in IoT sensor data\n",
        "\n",
        "### Next Steps:\n",
        "- Apply to real-world datasets (e.g., credit card fraud, network traffic)\n",
        "- Experiment with other PyOD algorithms (HBOS, COPOD, AutoEncoder)\n",
        "- Tune hyperparameters for optimal performance\n",
        "- Implement ensemble methods combining multiple detectors"
      ],
      "metadata": {
        "id": "vCEt5YiE6AeV"
      }
    }
  ]
}