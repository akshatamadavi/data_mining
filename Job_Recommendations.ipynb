{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0X3hdm+F8WFiK3nzXBm5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatamadavi/data_mining/blob/main/Job_Recommendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVzk5YcJYEr7"
      },
      "outputs": [],
      "source": [
        "# Job Recommendation System\n",
        "# Matches your resume and skills to New Grad positions from SimplifyJobs repo\n",
        "\n",
        "# Cell 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q gradio PyPDF2 pdfplumber spacy scikit-learn requests beautifulsoup4 pandas\n",
        "# !python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "gx9OQHUbZ1kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Libraries\n",
        "import gradio as gr\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import pdfplumber\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import io"
      ],
      "metadata": {
        "id": "d5vuSI7lZ4pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Fix Asyncio Event Loop for Colab + Gradio + CrewAI\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Reset the event loop\n",
        "try:\n",
        "    loop = asyncio.get_event_loop()\n",
        "    if loop.is_running():\n",
        "        loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(loop)\n",
        "except RuntimeError:\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "\n",
        "print(\"‚úÖ Asyncio event loop configured for Colab\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3R4u3LlfOVt",
        "outputId": "c2a01655-7274-423b-f021-590922819f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Asyncio event loop configured for Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "edgLg6vtaEw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Resume Parsing Function\n",
        "def parse_resume(pdf_file):\n",
        "    \"\"\"\n",
        "    Parse resume PDF to extract skills, education, and experience.\n",
        "    \"\"\"\n",
        "    if pdf_file is None:\n",
        "        return {\"skills\": [], \"education\": [], \"experience\": [], \"text\": \"\"}\n",
        "\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_file) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "    except Exception as e:\n",
        "        return {\"skills\": [], \"education\": [], \"experience\": [], \"text\": f\"Error: {str(e)}\"}\n",
        "\n",
        "    # Process with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract skills (simple keyword matching)\n",
        "    skill_keywords = [\"python\", \"java\", \"javascript\", \"c++\", \"sql\", \"react\", \"node\",\n",
        "                     \"machine learning\", \"data\", \"aws\", \"docker\", \"kubernetes\", \"tensorflow\",\n",
        "                     \"pytorch\", \"git\", \"agile\", \"scrum\", \"rest api\", \"mongodb\", \"postgresql\"]\n",
        "\n",
        "    skills = []\n",
        "    text_lower = text.lower()\n",
        "    for skill in skill_keywords:\n",
        "        if skill in text_lower:\n",
        "            skills.append(skill)\n",
        "\n",
        "    # Extract education (simple pattern matching)\n",
        "    education = []\n",
        "    education_keywords = [\"bachelor\", \"master\", \"phd\", \"bs\", \"ms\", \"b.s.\", \"m.s.\", \"university\", \"college\"]\n",
        "    for sent in doc.sents:\n",
        "        sent_text = sent.text.lower()\n",
        "        if any(keyword in sent_text for keyword in education_keywords):\n",
        "            education.append(sent.text.strip())\n",
        "\n",
        "    return {\n",
        "        \"skills\": list(set(skills)),\n",
        "        \"education\": education[:3],  # Limit to first 3 matches\n",
        "        \"text\": text\n",
        "    }"
      ],
      "metadata": {
        "id": "ZgHWi6mvaR3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Crawl SimplifyJobs - HTML Parser (WORKING!)\n",
        "def fetch_jobs():\n",
        "    url = \"https://raw.githubusercontent.com/SimplifyJobs/New-Grad-Positions/dev/README.md\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=15)\n",
        "        content = response.text\n",
        "\n",
        "        # Use BeautifulSoup to parse HTML tables\n",
        "        soup = BeautifulSoup(content, 'html.parser')\n",
        "        tables = soup.find_all('table')\n",
        "\n",
        "        jobs = []\n",
        "        for table in tables:\n",
        "            rows = table.find_all('tr')\n",
        "            for row in rows[1:]:  # Skip header\n",
        "                cells = row.find_all('td')\n",
        "                if len(cells) >= 3:\n",
        "                    company = cells[0].get_text(strip=True)\n",
        "                    role = cells[1].get_text(strip=True)\n",
        "                    location = cells[2].get_text(strip=True)\n",
        "\n",
        "                    if company and role:\n",
        "                        jobs.append({\n",
        "                            'company': company,\n",
        "                            'role': role,\n",
        "                            'location': location,\n",
        "                            'text': f\"{company} {role} {location}\"\n",
        "                        })\n",
        "\n",
        "        print(f\"‚úÖ Fetched {len(jobs)} jobs from {len(tables)} tables\")\n",
        "        return pd.DataFrame(jobs)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "M3dVRM58aWqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug: Test fetch_jobs function\n",
        "test_df = fetch_jobs()\n",
        "print(f\"Number of jobs fetched: {len(test_df)}\")\n",
        "print(f\"\\nFirst 3 jobs:\")\n",
        "if not test_df.empty:\n",
        "    print(test_df.head(3))\n",
        "else:\n",
        "    print(\"No jobs found - DataFrame is empty\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF3UrcGJcXeO",
        "outputId": "7ec11526-a287-4cf7-9d90-574f111c51ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fetched 1400 jobs from 12 tables\n",
            "Number of jobs fetched: 1400\n",
            "\n",
            "First 3 jobs:\n",
            "            company                                           role  \\\n",
            "0            Circle      New Grad Software Engineer - Backend 2026   \n",
            "1  American Express  Software Engineer 1 - Enterprise Architecture   \n",
            "2             CLEAR             Software Engineer ‚Äì New Grad - Web   \n",
            "\n",
            "                                            location  \\\n",
            "0  12 locationsSalt Lake City, UTBoston, MASeattl...   \n",
            "1                                         London, UK   \n",
            "2                                                NYC   \n",
            "\n",
            "                                                text  \n",
            "0  Circle New Grad Software Engineer - Backend 20...  \n",
            "1  American Express Software Engineer 1 - Enterpr...  \n",
            "2       CLEAR Software Engineer ‚Äì New Grad - Web NYC  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Job Matching Function\n",
        "def match_jobs(resume_file, visa_required, user_skills, job_type):\n",
        "    \"\"\"\n",
        "    Match user profile with job listings.\n",
        "    \"\"\"\n",
        "    # Parse resume\n",
        "    resume_data = parse_resume(resume_file)\n",
        "    resume_skills = resume_data['skills']\n",
        "\n",
        "    # Combine with user-entered skills\n",
        "    if user_skills:\n",
        "        extra_skills = [s.strip().lower() for s in user_skills.split(',')]\n",
        "        all_skills = list(set(resume_skills + extra_skills))\n",
        "    else:\n",
        "        all_skills = resume_skills\n",
        "\n",
        "    # Fetch jobs\n",
        "    jobs_df = fetch_jobs()\n",
        "\n",
        "    if jobs_df.empty:\n",
        "        return \"No jobs found. Please try again.\", pd.DataFrame(), f\"Parsed Skills: {all_skills}\"\n",
        "\n",
        "    # Filter by job type\n",
        "    if job_type == \"Internship\":\n",
        "        jobs_df = jobs_df[jobs_df['role'].str.contains('Intern', case=False, na=False)]\n",
        "    elif job_type in [\"Full-time\", \"Part-time\"]:\n",
        "        jobs_df = jobs_df[~jobs_df['role'].str.contains('Intern', case=False, na=False)]\n",
        "\n",
        "    # Filter by visa sponsorship (if required)\n",
        "    if visa_required:\n",
        "        # This is a placeholder - the repo doesn't always have visa info clearly marked\n",
        "        # You can enhance this based on actual data structure\n",
        "        pass\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    if len(all_skills) == 0:\n",
        "        return \"No skills found in resume. Please add skills manually.\", pd.DataFrame(), \"No skills detected\"\n",
        "\n",
        "    user_profile = \" \".join(all_skills)\n",
        "    job_texts = jobs_df['text'].tolist()\n",
        "\n",
        "    # Use TF-IDF to compute similarity\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    all_texts = [user_profile] + job_texts\n",
        "\n",
        "    try:\n",
        "        tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "        user_vector = tfidf_matrix[0:1]\n",
        "        job_vectors = tfidf_matrix[1:]\n",
        "\n",
        "        similarities = cosine_similarity(user_vector, job_vectors)[0]\n",
        "        jobs_df['score'] = similarities\n",
        "\n",
        "        # Get top 10\n",
        "        top_jobs = jobs_df.nlargest(10, 'score')[['company', 'role', 'location', 'score']]\n",
        "        top_jobs['score'] = top_jobs['score'].round(3)\n",
        "\n",
        "        summary = f\"\"\"üìã **Parsed Skills:** {', '.join(resume_skills)}\n",
        "üîß **All Skills Used:** {', '.join(all_skills)}\n",
        "üìö **Education:** {', '.join(resume_data['education']) if resume_data['education'] else 'Not detected'}\n",
        "üéØ **Job Type:** {job_type}\n",
        "‚úÖ **Total Jobs Found:** {len(jobs_df)}\n",
        "        \"\"\"\n",
        "\n",
        "        return summary, top_jobs, resume_data['text'][:500] + \"...\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", pd.DataFrame(), \"\""
      ],
      "metadata": {
        "id": "nwPH2A6kabxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Create Gradio Interface\n",
        "def create_interface():\n",
        "    with gr.Blocks(title=\"Job Recommendation System\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üöÄ New Grad Job Recommendation System\n",
        "        ### Match your resume with top New Grad positions from SimplifyJobs\n",
        "\n",
        "        Upload your resume, specify your preferences, and get personalized job recommendations!\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### üìù Input Your Details\")\n",
        "                resume_file = gr.File(label=\"Upload Resume (PDF)\", file_types=[\".pdf\"])\n",
        "                visa_required = gr.Checkbox(label=\"Visa Sponsorship Required?\", value=False)\n",
        "                user_skills = gr.Textbox(\n",
        "                    label=\"Additional Skills (comma-separated, optional)\",\n",
        "                    placeholder=\"e.g., Python, Machine Learning, AWS\"\n",
        "                )\n",
        "                job_type = gr.Radio(\n",
        "                    [\"Full-time\", \"Internship\", \"Part-time\"],\n",
        "                    label=\"Job Type\",\n",
        "                    value=\"Full-time\"\n",
        "                )\n",
        "                submit_btn = gr.Button(\"üîç Find Top 10 Jobs\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### üéØ Results\")\n",
        "                summary_output = gr.Markdown(label=\"Summary\")\n",
        "                jobs_output = gr.Dataframe(\n",
        "                    label=\"Top 10 Matching Jobs\",\n",
        "                    headers=[\"Company\", \"Role\", \"Location\", \"Match Score\"],\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        with gr.Accordion(\"üìÑ View Resume Text\", open=False):\n",
        "            resume_text_output = gr.Textbox(label=\"Parsed Resume Text (Preview)\", lines=5)\n",
        "\n",
        "        submit_btn.click(\n",
        "            fn=match_jobs,\n",
        "            inputs=[resume_file, visa_required, user_skills, job_type],\n",
        "            outputs=[summary_output, jobs_output, resume_text_output]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        üí° **Tips:**\n",
        "        - Make sure your resume clearly lists your skills and education\n",
        "        - Add extra skills in the text box if they're not detected\n",
        "        - Jobs are fetched live from [SimplifyJobs GitHub Repo](https://github.com/SimplifyJobs/New-Grad-Positions)\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_interface()\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "p15tdRB7aix4",
        "outputId": "5ff795fc-4c3e-4016-d328-1627f3ab5e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1157193030.py:3: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(title=\"Job Recommendation System\", theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a720b90ba1ed44839d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a720b90ba1ed44839d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fetched 1400 jobs from 12 tables\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a720b90ba1ed44839d.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# MULTI-AGENT JOB RECOMMENDATION SYSTEM\n",
        "# Using CrewAI for intelligent resume parsing\n",
        "# and job matching\n",
        "# ============================================"
      ],
      "metadata": {
        "id": "aw7FGvFubfms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Multi-Agent Dependencies\n",
        "!pip install -q crewai crewai-tools langchain-openai langchain-community\n",
        "!pip install -q pdfplumber PyPDF2"
      ],
      "metadata": {
        "id": "05ZgZGU3d8OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IX1k16GieBbi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}