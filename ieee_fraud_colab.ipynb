{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2055d36",
      "metadata": {
        "id": "d2055d36"
      },
      "source": [
        "# Colab-ready: AutoGluon + IEEE-CIS Fraud Detection\n",
        "\n",
        "This notebook combines the steps from the project's `tabular-kaggle.ipynb` and the existing Colab helper into a single, runnable Colab notebook. It will:\n",
        "- install packages,\n",
        "- show two ways to provide your `kaggle.json` (upload or Drive),\n",
        "- download the dataset via the Kaggle API,\n",
        "- merge CSVs, reduce memory, and optionally sample for quick runs,\n",
        "- train AutoGluon,\n",
        "- save predictions and optionally submit to Kaggle via the CLI.\n",
        "\n",
        "Run cells in order. New cells don't need IDs but existing ones do — this file is freshly created so cells have no `metadata.id`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1718c065",
      "metadata": {
        "id": "1718c065"
      },
      "source": [
        "## 1 — Install dependencies\n",
        "Run this cell first in Colab. It installs `kaggle` and `autogluon.tabular` plus common data packages. If any install fails, try a different AutoGluon version that matches Colab's Python runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e08467",
      "metadata": {
        "id": "c0e08467"
      },
      "outputs": [],
      "source": [
        "# Install required packages (run in Colab)\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install kaggle autogluon.tabular pandas numpy scikit-learn\n",
        "import sys, pandas as pd, numpy as np\n",
        "print('Python:', sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c9019ee",
      "metadata": {
        "id": "0c9019ee"
      },
      "source": [
        "## 2 — Provide your Kaggle API key (`kaggle.json`)\n",
        "\n",
        "Two recommended options:\n",
        "A) Upload interactively (one-off): use the upload cell below.\n",
        "B) Mount Google Drive (recommended for repeat runs): put `kaggle.json` in `MyDrive/.kaggle/kaggle.json` then run the Drive cell to copy it to `~/.kaggle/kaggle.json`.\n",
        "\n",
        "Important: never commit `kaggle.json` to source control. It contains your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83570af6",
      "metadata": {
        "id": "83570af6"
      },
      "outputs": [],
      "source": [
        "# Option A: Upload kaggle.json (interactive)\n",
        "from google.colab import files\n",
        "import os\n",
        "uploaded = files.upload()\n",
        "if 'kaggle.json' in uploaded:\n",
        "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "    open(os.path.expanduser('~/.kaggle/kaggle.json'), 'wb').write(uploaded['kaggle.json'])\n",
        "    os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
        "    print('Saved to ~/.kaggle/kaggle.json')\n",
        "else:\n",
        "    print('No kaggle.json uploaded. Use Drive option if preferred.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eaa8be6",
      "metadata": {
        "id": "0eaa8be6"
      },
      "outputs": [],
      "source": [
        "# Option B: Mount Google Drive and copy kaggle.json from MyDrive/.kaggle/\n",
        "from google.colab import drive\n",
        "import shutil, os\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/.kaggle/kaggle.json'\n",
        "if os.path.exists(drive_path):\n",
        "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "    shutil.copy(drive_path, os.path.expanduser('~/.kaggle/kaggle.json'))\n",
        "    os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
        "    print('Copied kaggle.json from Drive to ~/.kaggle/kaggle.json')\n",
        "else:\n",
        "    print('No kaggle.json found in Drive at', drive_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a9691d6",
      "metadata": {
        "id": "5a9691d6"
      },
      "source": [
        "## 3 — Download dataset via Kaggle API\n",
        "This will download and unzip the competition data into `/content/data`. Ensure you have accepted the competition rules on the Kaggle website first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73feb9b0",
      "metadata": {
        "id": "73feb9b0"
      },
      "outputs": [],
      "source": [
        "# Download and unzip\n",
        "competition = 'ieee-fraud-detection'\n",
        "import os\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "!kaggle competitions download -c $competition -p /content/data --quiet\n",
        "!unzip -oq /content/data/{competition}.zip -d /content/data || true\n",
        "print('Done. Files:')\n",
        "!ls -lh /content/data | sed -n '1,120p'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad77cba6",
      "metadata": {
        "id": "ad77cba6"
      },
      "source": [
        "## 4 — Load, merge, and reduce memory\n",
        "We left-join transaction with identity on `TransactionID`. We also include a utility to downcast numeric columns to reduce memory usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72d11a8",
      "metadata": {
        "id": "b72d11a8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, os\n",
        "DATA_DIR = '/content/data'\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if pd.api.types.is_numeric_dtype(col_type):\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if pd.api.types.is_integer_dtype(col_type):\n",
        "                if c_min >= 0:\n",
        "                    if c_max < 255:\n",
        "                        df[col] = df[col].astype(np.uint8)\n",
        "                    elif c_max < 65535:\n",
        "                        df[col] = df[col].astype(np.uint16)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.uint32)\n",
        "                else:\n",
        "                    df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "            else:\n",
        "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
        "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    if verbose:\n",
        "        print(f'Memory: {start_mem:,.2f} MB -> {end_mem:,.2f} MB')\n",
        "    return df\n",
        "# Read files\n",
        "paths = {\n",
        "    'train_transaction': os.path.join(DATA_DIR, 'train_transaction.csv'),\n",
        "    'train_identity': os.path.join(DATA_DIR, 'train_identity.csv'),\n",
        "    'test_transaction': os.path.join(DATA_DIR, 'test_transaction.csv'),\n",
        "    'test_identity': os.path.join(DATA_DIR, 'test_identity.csv'),\n",
        "    'sample_submission': os.path.join(DATA_DIR, 'sample_submission.csv'),\n",
        "}\n",
        "for k,p in paths.items():\n",
        "    print(k, '->', os.path.exists(p))\n",
        "train_tr = pd.read_csv(paths['train_transaction'], low_memory=False)\n",
        "train_id = pd.read_csv(paths['train_identity'], low_memory=False)\n",
        "test_tr  = pd.read_csv(paths['test_transaction'], low_memory=False)\n",
        "test_id  = pd.read_csv(paths['test_identity'], low_memory=False)\n",
        "train = train_tr.merge(train_id, on='TransactionID', how='left')\n",
        "test  = test_tr.merge(test_id, on='TransactionID', how='left')\n",
        "train = reduce_mem_usage(train)\n",
        "test = reduce_mem_usage(test)\n",
        "print('train shape', train.shape, 'test shape', test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cdfb158",
      "metadata": {
        "id": "6cdfb158"
      },
      "source": [
        "## 5 — Optional: sample for quicker experiments\n",
        "Set `USE_SAMPLE=True` to run a quick baseline. This helps when Colab runs out of RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e79fb09",
      "metadata": {
        "id": "0e79fb09"
      },
      "outputs": [],
      "source": [
        "USE_SAMPLE = False\n",
        "SAMPLE_FRAC = 0.1\n",
        "if USE_SAMPLE:\n",
        "    train = train.sample(frac=SAMPLE_FRAC, random_state=42)\n",
        "    print('Sampled train shape:', train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b40b0737",
      "metadata": {
        "id": "b40b0737"
      },
      "source": [
        "## 6 — Train AutoGluon TabularPredictor\n",
        "We use `isFraud` as the label. Adjust `time_limit` and `presets` as needed. For large jobs, save the model directory to Drive after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a22ac64",
      "metadata": {
        "id": "0a22ac64"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "label = 'isFraud'\n",
        "if label not in train.columns:\n",
        "    raise SystemExit(f'Label {label} not in train')\n",
        "cols_to_drop = ['TransactionID']\n",
        "train_features = train.drop(columns=[c for c in cols_to_drop if c in train.columns])\n",
        "test_features = test.drop(columns=[c for c in cols_to_drop if c in test.columns])\n",
        "save_path = '/content/ag_models'\n",
        "predictor = TabularPredictor(label=label, path=save_path, eval_metric='roc_auc').fit(train_features, presets='medium_quality', time_limit=1800)\n",
        "print(predictor.fit_summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6ef67d",
      "metadata": {
        "id": "4b6ef67d"
      },
      "source": [
        "## 7 — Predict & prepare submission\n",
        "We predict class probabilities and write the `submission.csv` expected by the competition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "168c46cb",
      "metadata": {
        "id": "168c46cb"
      },
      "outputs": [],
      "source": [
        "proba = predictor.predict_proba(test_features)\n",
        "import pandas as pd\n",
        "if isinstance(proba, pd.DataFrame):\n",
        "    # pick positive class probability\n",
        "    if 1 in proba.columns:\n",
        "        preds = proba[1]\n",
        "    else:\n",
        "        preds = proba.iloc[:, -1]\n",
        "else:\n",
        "    preds = proba\n",
        "submission = pd.read_csv(paths['sample_submission'])\n",
        "submission['isFraud'] = preds\n",
        "submission.to_csv('/content/submission.csv', index=False)\n",
        "print('Saved /content/submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "624bb69a",
      "metadata": {
        "id": "624bb69a"
      },
      "source": [
        "## 8 — Submit to Kaggle (optional)\n",
        "You can submit via the Kaggle CLI. If you prefer, download `/content/submission.csv` and upload manually on the competition page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ec0be0",
      "metadata": {
        "id": "45ec0be0"
      },
      "outputs": [],
      "source": [
        "# Kaggle submit (uncomment to run)\n",
        "# competition = 'ieee-fraud-detection'\n",
        "# !kaggle competitions submit -c $competition -f /content/submission.csv -m 'AutoGluon colab submission'\n",
        "print('To submit: run kaggle competitions submit -c ieee-fraud-detection -f /content/submission.csv -m\n",
        "')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ddb73e8",
      "metadata": {
        "id": "9ddb73e8"
      },
      "source": [
        "---\n",
        "### Notes:\n",
        "- Keep `kaggle.json` private.\n",
        "- For reproducibility, save `/content/ag_models` to Drive after training.\n",
        "- If Colab runs out of RAM, try a smaller sample or use a larger VM."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}