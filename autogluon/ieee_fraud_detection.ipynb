{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatamadavi/data_mining/blob/main/autogluon/ieee_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IEEE-CIS Fraud Detection\n",
        "Can you detect fraud from customer transactions?\n",
        "\n",
        "Description\n",
        "Imagine standing at the check-out counter at the grocery store with a long line behind you and the cashier not-so-quietly announces that your card has been declined. In this moment, you probably aren’t thinking about the data science that determined your fate.\n",
        "\n",
        "Embarrassed, and certain you have the funds to cover everything needed for an epic nacho party for 50 of your closest friends, you try your card again. Same result. As you step aside and allow the cashier to tend to the next customer, you receive a text message from your bank. “Press 1 if you really tried to spend $500 on cheddar cheese.”\n",
        "\n",
        "While perhaps cumbersome (and often embarrassing) in the moment, this fraud prevention system is actually saving consumers millions of dollars per year. Researchers from the IEEE Computational Intelligence Society (IEEE-CIS) want to improve this figure, while also improving the customer experience. With higher accuracy fraud detection, you can get on with your chips without the hassle.\n",
        "\n",
        "IEEE-CIS works across a variety of AI and machine learning areas, including deep neural networks, fuzzy systems, evolutionary computation, and swarm intelligence. Today they’re partnering with the world’s leading payment service company, Vesta Corporation, seeking the best solutions for fraud prevention industry, and now you are invited to join the challenge.\n",
        "\n",
        "In this competition, you’ll benchmark machine learning models on a challenging large-scale dataset. The data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results.\n",
        "\n",
        "If successful, you’ll improve the efficacy of fraudulent transaction alerts for millions of people around the world, helping hundreds of thousands of businesses reduce their fraud loss and increase their revenue. And of course, you will save party people just like you the hassle of false positives.\n",
        "\n",
        "Acknowledgements:\n",
        "\n",
        "\n",
        "\n",
        "Vesta Corporation provided the dataset for this competition. Vesta Corporation is the forerunner in guaranteed e-commerce payment solutions. Founded in 1995, Vesta pioneered the process of fully guaranteed card-not-present (CNP) payment transactions for the telecommunications industry. Since then, Vesta has firmly expanded data science and machine learning capabilities across the globe and solidified its position as the leader in guaranteed ecommerce payments. Today, Vesta guarantees more than $18B in transactions annually.\n",
        "\n",
        "Header Photo by Tim Evans on Unsplash"
      ],
      "metadata": {
        "id": "vfjK746zu_dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##This tutorial will teach you how to use AutoGluon to become a serious Kaggle competitor without writing lots of code. We first outline the general steps to use AutoGluon in Kaggle contests. Here, we assume the competition involves tabular data which are stored in one (or more) CSV files."
      ],
      "metadata": {
        "id": "Y0BOSwyddsnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Run Bash command: pip install kaggle!"
      ],
      "metadata": {
        "id": "dgKr8U6mdzBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U kaggle"
      ],
      "metadata": {
        "id": "CLRO5V3Eqk2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Navigate to: https://www.kaggle.com/account and create an account (if necessary). Then , click on “Create New API Token” and move downloaded file to this location on your machine: ~/.kaggle/kaggle.json. For troubleshooting, see Kaggle API instructions."
      ],
      "metadata": {
        "id": "JaURpznQeOAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # choose kaggle.json you downloaded from Kaggle > Account > Create New API Token\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "8iBrAWKcqrOX",
        "outputId": "deadef74-6d1d-436d-c81f-e15baa3d3543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a14f08f-6701-4819-9505-b4d34b904ab0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a14f08f-6701-4819-9505-b4d34b904ab0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. To download data programmatically: Execute this Bash command in your terminal:\n",
        "\n",
        "kaggle competitions download -c [COMPETITION]\n",
        "\n",
        "Here, [COMPETITION] should be replaced by the name of the competition you wish to enter. Alternatively, you can download data manually: Just navigate to website of the Kaggle competition you wish to enter, click “Download All”, and accept the competition’s terms."
      ],
      "metadata": {
        "id": "NVaTJ7TigZ8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "p = os.path.expanduser('~/.kaggle/kaggle.json')\n",
        "creds = json.load(open(p))\n",
        "print(\"Using Kaggle account:\", creds[\"username\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_cKGFKWqwUL",
        "outputId": "4ebb4888-b193-4f30-aecc-538d010ee81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Kaggle account: akshatamadavi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions files -c ieee-fraud-detection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kXynXzWqzYg",
        "outputId": "9f7e8928-a9ee-4f86-fe81-e0ec051753a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name                         size  creationDate                \n",
            "---------------------  ----------  --------------------------  \n",
            "sample_submission.csv     6080314  2019-07-15 00:19:01.536000  \n",
            "test_identity.csv        25797161  2019-07-15 00:19:01.536000  \n",
            "test_transaction.csv    613194934  2019-07-15 00:19:01.536000  \n",
            "train_identity.csv       26529680  2019-07-15 00:19:01.536000  \n",
            "train_transaction.csv   683351067  2019-07-15 00:19:01.536000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection -p /content -w\n",
        "# (The competition slug is all lowercase: ieee-fraud-detection)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqg53dR9q55c",
        "outputId": "b19334bb-6d71-4762-87d1-81da00a7fa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to .\n",
            "\r  0% 0.00/118M [00:00<?, ?B/s]\n",
            "\r100% 118M/118M [00:00<00:00, 3.23GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. If the competition’s training data is comprised of multiple CSV files, use pandas to properly merge/join them into a single data table where rows = training examples, columns = features."
      ],
      "metadata": {
        "id": "xlu9iSuszT8k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54d086bd",
        "outputId": "8d93cc8d-7c2b-4041-de94-627fe29be29a"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/ieee-fraud-detection.zip'\n",
        "destination_path = '/content/'\n",
        "\n",
        "if os.path.exists(zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_path)\n",
        "    print(f\"Extracted {zip_file_path} to {destination_path}\")\n",
        "else:\n",
        "    print(f\"Error: {zip_file_path} not found. Please ensure the competition data is downloaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted /content/ieee-fraud-detection.zip to /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4(a): we first load the competition’s training data into Python:"
      ],
      "metadata": {
        "id": "h5zNVnfH24Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI5Vn7Xz9IEE",
        "outputId": "f7bbb520-5ac4-4b8f-c6e7-dc113b2d34a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = Path(\"/content\")  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory/'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory/'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory/'train_transaction.csv')"
      ],
      "metadata": {
        "id": "9vAr2fH21fHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4(b):Since the training data for this competition is comprised of multiple CSV files, we just first join them into a single large table (with rows = examples, columns = features) before applying AutoGluon:"
      ],
      "metadata": {
        "id": "409kxRWA3Ngp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "2zRPz8943N30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4(c):we specify the presets argument to maximize AutoGluon’s predictive accuracy which usually requires that you run fit()"
      ],
      "metadata": {
        "id": "sfS909fY3oJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='best_quality', time_limit=3600\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP2Dhb0m3q-f",
        "outputId": "5c63af20-7e4a-433a-e158-bb4b94394afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          8\n",
            "GPU Count:          0\n",
            "Memory Avail:       43.83 GB / 50.99 GB (86.0%)\n",
            "Disk Space Avail:   178.86 GB / 225.83 GB (79.2%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True, 'num_bag_sets': 1}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-10-14 23:05:21,948\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Beginning AutoGluon training ... Time limit = 896s\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m AutoGluon will save models to \"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Train Data Rows:    524924\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Train Data Columns: 433\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Label Column:       isFraud\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tAvailable Memory:                    40345.71 MB\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTrain Data (Original)  Memory Usage: 2231.12 MB (5.5% of available memory)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tWarning: Data size prior to feature transformation consumes 5.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t4.8s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t4.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t0.4s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t1.0s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t2.7s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t3 duplicate columns removed: ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t3.7s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t\t430 features in original data used to generate 430 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tUnused Original Features (Count: 3): ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('float', []) : 3 | ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('float64', 'float') : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('float', [])  : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('float64', 'float')     : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t27.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t430 features in original data used to generate 430 features in processed data.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTrain Data (Processed) Memory Usage: 1614.47 MB (4.0% of available memory)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Data preprocessing and feature engineering runtime = 32.43s ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 575.48s of the 863.42s of remaining time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 27.94% memory usage per fold, 55.88%/80.00% total).\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=27.94%)\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0947332\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0856834\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0811864\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0779008\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [250]\tvalid_set's binary_logloss: 0.075393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0733887\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0715076\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m [450]\tvalid_set's binary_logloss: 0.0709354\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0686913\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [600]\tvalid_set's binary_logloss: 0.0658586\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m [700]\tvalid_set's binary_logloss: 0.0663225\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [750]\tvalid_set's binary_logloss: 0.0633645\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m [850]\tvalid_set's binary_logloss: 0.0644489\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m [900]\tvalid_set's binary_logloss: 0.0614173\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m \tRan out of time, early stopping on iteration 995. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m \t[995]\tvalid_set's binary_logloss: 0.0629932\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=4677)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F2/model.pkl\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m \tRan out of time, early stopping on iteration 979. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m \t[979]\tvalid_set's binary_logloss: 0.0603987\n",
            "\u001b[36m(_ray_fit pid=4676)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F1/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0972117\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [100]\tvalid_set's binary_logloss: 0.088068\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0833867\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0802051\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0777755\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0757618\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0703856\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [450]\tvalid_set's binary_logloss: 0.0715822\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0667224\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0658066\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [650]\tvalid_set's binary_logloss: 0.0676668\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [700]\tvalid_set's binary_logloss: 0.0669192\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m [750]\tvalid_set's binary_logloss: 0.0624692\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [850]\tvalid_set's binary_logloss: 0.0648568\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m [950]\tvalid_set's binary_logloss: 0.0636478\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m \tRan out of time, early stopping on iteration 977. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m \t[977]\tvalid_set's binary_logloss: 0.0633687\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=5299)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F3/model.pkl\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m \tRan out of time, early stopping on iteration 977. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m \t[977]\tvalid_set's binary_logloss: 0.0596786\n",
            "\u001b[36m(_ray_fit pid=5300)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F4/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0947801\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [100]\tvalid_set's binary_logloss: 0.085936\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0804302\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0790555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0746041\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0725095\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m [350]\tvalid_set's binary_logloss: 0.072986\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m [400]\tvalid_set's binary_logloss: 0.071683\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0670411\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0660105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m [600]\tvalid_set's binary_logloss: 0.0672731\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [700]\tvalid_set's binary_logloss: 0.0633625\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m [750]\tvalid_set's binary_logloss: 0.0649947\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [850]\tvalid_set's binary_logloss: 0.0613766\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m [900]\tvalid_set's binary_logloss: 0.0632384\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0595751\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m \tRan out of time, early stopping on iteration 1010. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m \t[1010]\tvalid_set's binary_logloss: 0.0594578\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F5/model.pkl\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m \tRan out of time, early stopping on iteration 991. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=5914)\u001b[0m \t[990]\tvalid_set's binary_logloss: 0.0622165\n",
            "\u001b[36m(_ray_fit pid=5919)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F6/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0953804\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0948859\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0866564\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0859983\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0819336\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0813892\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0780416\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0786712\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0754078\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0763081\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0731009\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0743573\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0727327\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [400]\tvalid_set's binary_logloss: 0.070046\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0689836\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0679652\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [650]\tvalid_set's binary_logloss: 0.0662682\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m [700]\tvalid_set's binary_logloss: 0.0654815\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m [800]\tvalid_set's binary_logloss: 0.0625517\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m \tRan out of time, early stopping on iteration 799. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=6529)\u001b[0m \t[799]\tvalid_set's binary_logloss: 0.0640687\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F8/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.9514\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t483.16s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t23.87s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t2749.2\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 80.90s of the 368.84s of remaining time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m \tRan out of time, early stopping on iteration 814. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=6528)\u001b[0m \t[814]\tvalid_set's binary_logloss: 0.0623486\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 29.18% memory usage per fold, 58.36%/80.00% total).\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=29.18%)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=7250)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7250)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7250)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.139122\n",
            "\u001b[36m(_ray_fit pid=7249)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7250)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F1/model.pkl\n",
            "\u001b[36m(_ray_fit pid=7453)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7249)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7249)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.139268\n",
            "\u001b[36m(_ray_fit pid=7249)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F2/model.pkl\n",
            "\u001b[36m(_ray_fit pid=7453)\u001b[0m \tRan out of time, early stopping on iteration 10. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7453)\u001b[0m \t[10]\tvalid_set's binary_logloss: 0.112559\n",
            "\u001b[36m(_ray_fit pid=7451)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7453)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F4/model.pkl\n",
            "\u001b[36m(_ray_fit pid=7643)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7451)\u001b[0m \tRan out of time, early stopping on iteration 6. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7451)\u001b[0m \t[6]\tvalid_set's binary_logloss: 0.122496\n",
            "\u001b[36m(_ray_fit pid=7451)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F3/model.pkl\n",
            "\u001b[36m(_ray_fit pid=7643)\u001b[0m \tRan out of time, early stopping on iteration 13. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7643)\u001b[0m \t[13]\tvalid_set's binary_logloss: 0.109851\n",
            "\u001b[36m(_ray_fit pid=7642)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7642)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F5/model.pkl\n",
            "\u001b[36m(_ray_fit pid=7833)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=7642)\u001b[0m \tRan out of time, early stopping on iteration 4. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7642)\u001b[0m \t[4]\tvalid_set's binary_logloss: 0.126896\n",
            "\u001b[36m(_ray_fit pid=7643)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F6/model.pkl\n",
            "\u001b[36m(_ray_fit pid=7831)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7831)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.116149\n",
            "\u001b[36m(_ray_fit pid=7831)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.8351\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t80.74s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t1.13s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t58080.0\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 280.77s of remaining time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m [1. 0.]\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.94s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_ray_fit pid=7833)\u001b[0m \tRan out of time, early stopping on iteration 5. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=7833)\u001b[0m \t[5]\tvalid_set's binary_logloss: 0.123618\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.9514\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t5.41s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t2747.7\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 275.24s of the 274.64s of remaining time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.66% memory usage per fold, 61.32%/80.00% total).\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.66%)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m [50]\tvalid_set's binary_logloss: 0.066489\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0691349\n",
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0619952\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0641302\n",
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0604586\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0622381\n",
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0592156\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0603236\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0589189\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m [300]\tvalid_set's binary_logloss: 0.058122\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m \tRan out of time, early stopping on iteration 335. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m \t[335]\tvalid_set's binary_logloss: 0.0570324\n",
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F1/model.pkl\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m \tRan out of time, early stopping on iteration 315. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=8161)\u001b[0m \t[315]\tvalid_set's binary_logloss: 0.0579649\n",
            "\u001b[36m(_ray_fit pid=8160)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0665779\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0729042\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0666059\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0613788\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0633225\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0590339\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0578096\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0606734\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0569658\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0593816\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0582874\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m \tRan out of time, early stopping on iteration 324. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m \t[324]\tvalid_set's binary_logloss: 0.056099\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=8518)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F3/model.pkl\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m \tRan out of time, early stopping on iteration 311. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m \t[311]\tvalid_set's binary_logloss: 0.058138\n",
            "\u001b[36m(_ray_fit pid=8519)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F4/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0717959\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0743618\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0656099\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0669291\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0631139\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0636332\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0615359\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0610246\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0601346\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0595749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m \tRan out of time, early stopping on iteration 320. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m \t[320]\tvalid_set's binary_logloss: 0.0585341\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=8876)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F5/model.pkl\n",
            "\u001b[36m(_ray_fit pid=9235)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m \tRan out of time, early stopping on iteration 327. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m \t[327]\tvalid_set's binary_logloss: 0.058179\n",
            "\u001b[36m(_ray_fit pid=8877)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F6/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0674543\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0618775\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9235)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0601212\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0575264\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0564409\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9235)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0565652\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=9235)\u001b[0m \tRan out of time, early stopping on iteration 336. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9235)\u001b[0m \t[336]\tvalid_set's binary_logloss: 0.0560847\n",
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=9235)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F7/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.9566\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t237.09s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t9.96s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t1876.8\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 30.13s of the 29.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.63% memory usage per fold, 61.26%/80.00% total).\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.63%)\n",
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m \tRan out of time, early stopping on iteration 350. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9236)\u001b[0m \t[350]\tvalid_set's binary_logloss: 0.0553463\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=9706)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9706)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9706)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.123368\n",
            "\u001b[36m(_ray_fit pid=9707)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9706)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F1/model.pkl\n",
            "\u001b[36m(_ray_fit pid=9887)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9707)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9707)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.123183\n",
            "\u001b[36m(_ray_fit pid=9707)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F2/model.pkl\n",
            "\u001b[36m(_ray_fit pid=9887)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9887)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.122601\n",
            "\u001b[36m(_ray_fit pid=9930)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9887)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F3/model.pkl\n",
            "\u001b[36m(_ray_fit pid=10069)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=9930)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=9930)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.123319\n",
            "\u001b[36m(_ray_fit pid=9930)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F4/model.pkl\n",
            "\u001b[36m(_ray_fit pid=10069)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=10069)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.123451\n",
            "\u001b[36m(_ray_fit pid=10116)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=10069)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F5/model.pkl\n",
            "\u001b[36m(_ray_fit pid=10259)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=10116)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=10116)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.122446\n",
            "\u001b[36m(_ray_fit pid=10116)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F6/model.pkl\n",
            "\u001b[36m(_ray_fit pid=10259)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=10259)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.122842\n",
            "\u001b[36m(_ray_fit pid=10260)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_ray_fit pid=10259)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F7/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.94\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t73.82s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.89s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t2534.3\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -51.04s of remaining time.\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Ensemble size: 3\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m [0.         0.         0.66666667 0.33333333]\n",
            "\u001b[36m(_ray_fit pid=10260)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=10260)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.122403\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.99s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.667, 'LightGBM_BAG_L2': 0.333}\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.9566\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t10.73s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t0.09s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m \t1829.5\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m AutoGluon training complete, total runtime = 965.62s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1829.5 rows/s (65616 batch size)\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.4.0\"\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=3891)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L2       0.962915   0.956632     roc_auc       22.206491      34.961116  800.991179                 4.902678                9.963906         237.089913            2       True          4\n",
            "1  WeightedEnsemble_L3       0.962809   0.956636     roc_auc       22.897983      35.945243  885.534484                 0.003407                0.090339          10.726549            3       True          6\n",
            "2    LightGBMXT_BAG_L1       0.953401   0.951386     roc_auc       16.442604      23.867458  483.162582                16.442604               23.867458         483.162582            1       True          1\n",
            "3  WeightedEnsemble_L2       0.953401   0.951386     roc_auc       16.445422      23.968608  488.570115                 0.002819                0.101150           5.407532            2       True          3\n",
            "4      LightGBM_BAG_L2       0.943663   0.940048     roc_auc       17.991898      25.890998  637.718022                 0.688085                0.893788          73.816756            2       True          5\n",
            "5      LightGBM_BAG_L1       0.863728   0.835104     roc_auc        0.861209       1.129751   80.738684                 0.861209                1.129751          80.738684            1       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t1006s\t = DyStack   runtime |\t2594s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 2594s\n",
            "AutoGluon will save models to \"/content/AutoGluonModels\"\n",
            "Train Data Rows:    590540\n",
            "Train Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    40915.98 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2531.61 MB (6.2% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 6.2% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t3.0s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.6s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.3s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.1s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.2s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t3.1s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t4 duplicate columns removed: ['V28', 'V154', 'V155', 'V156']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t429 features in original data used to generate 429 features in processed data.\n",
            "\tUnused Original Features (Count: 4): ['V28', 'V154', 'V155', 'V156']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 4 | ['V28', 'V154', 'V155', 'V156']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t19.8s = Fit runtime\n",
            "\t429 features in original data used to generate 429 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1811.77 MB (4.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 22.39s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "}\n",
            "Saving /content/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y.pkl\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1714.05s of the 2571.59s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.40% memory usage per fold, 60.79%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.40%)\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\t0.9668\t = Validation score   (roc_auc)\n",
            "\t1418.64s\t = Training   runtime\n",
            "\t84.33s\t = Validation runtime\n",
            "\t875.4\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 277.22s of the 1134.76s of remaining time.\n",
            "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.38% memory usage per fold, 60.75%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.38%)\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "\t0.9396\t = Validation score   (roc_auc)\n",
            "\t238.2s\t = Training   runtime\n",
            "\t11.02s\t = Validation runtime\n",
            "\t6698.9\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 30.22s of the 887.76s of remaining time.\n",
            "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\tWarning: Model is expected to require 379.6s to train, which exceeds the maximum time limit of 25.5s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 18.72s of the 876.27s of remaining time.\n",
            "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
            "\tWarning: Model is expected to require 348.9s to train, which exceeds the maximum time limit of 14.0s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 8.10s of the 865.64s of remaining time.\n",
            "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 33.10% memory usage per fold, 66.21%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=33.10%)\n",
            "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 855.59s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "2025-10-14 23:51:15,151\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1. 0.]\n",
            "\t0.86s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.9668\t = Validation score   (roc_auc)\n",
            "\t5.43s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "\t875.3\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 850.01s of the 849.58s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 32.12% memory usage per fold, 64.24%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=32.12%)\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\t0.97\t = Validation score   (roc_auc)\n",
            "\t707.67s\t = Training   runtime\n",
            "\t32.24s\t = Validation runtime\n",
            "\t578.6\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 131.96s of the 131.52s of remaining time.\n",
            "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 32.15% memory usage per fold, 64.31%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=32.15%)\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "\t0.9695\t = Validation score   (roc_auc)\n",
            "\t119.09s\t = Training   runtime\n",
            "\t2.05s\t = Validation runtime\n",
            "\t757.9\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.18s of remaining time.\n",
            "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Ensemble size: 7\n",
            "Ensemble weights: \n",
            "[0.         0.         0.57142857 0.42857143]\n",
            "\t1.15s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.571, 'LightGBM_BAG_L2': 0.429}\n",
            "\t0.9707\t = Validation score   (roc_auc)\n",
            "\t10.24s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "\t569.4\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 2606.69s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 569.4 rows/s (73818 batch size)\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Saving /content/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels\")\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3   0.970703     roc_auc     129.732271  2493.838254                0.098900          10.238527            3       True          6\n",
            "1    LightGBMXT_BAG_L2   0.970024     roc_auc     127.582366  2364.513823               32.236678         707.670918            2       True          4\n",
            "2      LightGBM_BAG_L2   0.969456     roc_auc      97.396693  1775.928809                2.051005         119.085905            2       True          5\n",
            "3    LightGBMXT_BAG_L1   0.966753     roc_auc      84.326269  1418.641238               84.326269        1418.641238            1       True          1\n",
            "4  WeightedEnsemble_L2   0.966753     roc_auc      84.429683  1424.069423                0.103414           5.428186            2       True          3\n",
            "5      LightGBM_BAG_L1   0.939581     roc_auc      11.019419   238.201667               11.019419         238.201667            1       True          2\n",
            "Number of models trained: 6\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "Plot summary of models saved to file: /content/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "directory = Path(\"/content\")\n",
        "ID_COL = \"TransactionID\"\n",
        "LABEL  = \"isFraud\"  # your training label\n",
        "\n",
        "# --- load & merge test ---\n",
        "test_identity    = pd.read_csv(directory/\"test_identity.csv\")\n",
        "test_transaction = pd.read_csv(directory/\"test_transaction.csv\")\n",
        "test_data = test_transaction.merge(test_identity, on=ID_COL, how=\"left\")\n",
        "\n",
        "# drop accidental index columns\n",
        "test_data = test_data.loc[:, ~test_data.columns.astype(str).str.startswith(\"Unnamed\")]\n",
        "\n",
        "# don't pass target\n",
        "if LABEL in test_data.columns:\n",
        "    test_data = test_data.drop(columns=[LABEL])\n",
        "\n",
        "# --- align to exactly the features used in training ---\n",
        "feat = predictor.features()            # the columns AutoGluon expects\n",
        "test_data = test_data.reindex(columns=feat)   # no fill_value; new cols will be NaN\n",
        "\n",
        "# --- make dtypes NumPy-friendly; replace pd.NA with np.nan ---\n",
        "test_data = test_data.replace({pd.NA: np.nan})\n",
        "\n",
        "for col in test_data.columns:\n",
        "    dt = test_data[col].dtype\n",
        "    # pandas nullable integers (Int64/Int32/Int16) -> float (allows np.nan)\n",
        "    if str(dt) in {\"Int64\", \"Int32\", \"Int16\", \"UInt64\", \"UInt32\", \"UInt16\"}:\n",
        "        test_data[col] = test_data[col].astype(\"float32\")\n",
        "    # pandas nullable boolean -> float (0.0/1.0 + nan)\n",
        "    elif str(dt) == \"boolean\":\n",
        "        test_data[col] = test_data[col].astype(\"float32\")\n",
        "    # pandas string dtype -> plain object (np.nan-compatible)\n",
        "    elif pd.api.types.is_string_dtype(dt):\n",
        "        test_data[col] = test_data[col].astype(\"object\")\n",
        "\n",
        "# --- predict ---\n",
        "y_predproba = predictor.predict_proba(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEZwtVD2ABVF",
        "outputId": "8f1b01d1-98a5-40b4-f0b3-ec07084408eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Igbozy6iqAK4",
        "outputId": "b8a7ec01-ad68-4eed-b392-5d6b687691a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1\n",
              "0  0.998561  0.001439\n",
              "1  0.998815  0.001185\n",
              "2  0.997428  0.002572\n",
              "3  0.998495  0.001505\n",
              "4  0.998787  0.001213"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9854ba47-a78b-4d9f-bb1e-74334f5936fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.998561</td>\n",
              "      <td>0.001439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.998815</td>\n",
              "      <td>0.001185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.997428</td>\n",
              "      <td>0.002572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.998495</td>\n",
              "      <td>0.001505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.998787</td>\n",
              "      <td>0.001213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9854ba47-a78b-4d9f-bb1e-74334f5936fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9854ba47-a78b-4d9f-bb1e-74334f5936fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9854ba47-a78b-4d9f-bb1e-74334f5936fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e5a3c99-e777-424f-a714-f0c87c2d4db7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e5a3c99-e777-424f-a714-f0c87c2d4db7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e5a3c99-e777-424f-a714-f0c87c2d4db7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_predproba"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For binary classification tasks, you can see which class AutoGluon’s predicted probabilities correspond to via:"
      ],
      "metadata": {
        "id": "8ssIqAukqnXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MYNmAocqiTO",
        "outputId": "8612b52a-5c89-4d2b-97d9-06710ea5ba56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiclass classification tasks, you can see which classes AutoGluon’s predicted probabilities correspond to via:"
      ],
      "metadata": {
        "id": "W2mcQAbHqrbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w0vGiD7quh7",
        "outputId": "ef0296f5-81b2-47de-e6a2-d8a53a91a825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s get prediction probabilities for the entire test data, while only getting the positive class predictions by specifying:"
      ],
      "metadata": {
        "id": "-3lKccwOq961"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLBNC5A-rAeU",
        "outputId": "5a905034-9f33-4bcc-aeb8-f83bbac492ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have made a prediction for each row in the test dataset, we can submit these predictions to Kaggle. Most Kaggle competitions provide a sample submission file, in which you can simply overwrite the sample predictions with your own as we do below:"
      ],
      "metadata": {
        "id": "MiSqhC1PrJLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory/'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory/'archie_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "7lveNz8PrKBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To submit your predictions to Kaggle, you can run the following command in your terminal"
      ],
      "metadata": {
        "id": "aOtzXvXgtz6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f archie_submission.csv -m \"my first submission\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZPLeDeatqwD",
        "outputId": "bf4c12c9-bbe2-4a00-a3dc-51191a76ec6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401 Client Error: Unauthorized for url: https://www.kaggle.com/api/v1/competitions/submission-url\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "piOkedbYnbPg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}