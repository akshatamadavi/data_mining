{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatamadavi/data_mining/blob/main/autogluon/AutoGluon_Multimodal_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "id": "92968322",
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ðŸ§  AutoGluon Multimodal (AutoMM) â€” Colab Tutorial\n",
        "\n",
        "This notebook walks through **AutoGluon Multimodal** (AutoMM) covering installation, dataset prep, training, evaluation, prediction, and model saving/loading â€” mirroring the official tutorial structure.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Setup Colab with GPU + install AutoGluon\n",
        "2. Download and prepare the **PetFinder** sample dataset (image + text + tabular)\n",
        "3. Train a **`MultiModalPredictor`** for classification\n",
        "4. Evaluate on a test split and inspect metrics\n",
        "5. Generate predictions & probabilities\n",
        "6. Save & reload the trained model for later inference\n",
        "\n",
        "> **Tip:** In Colab, go to **Runtime â†’ Change runtime type â†’ GPU** (T4 or A100). You can verify with `nvidia-smi` below.\n"
      ],
      "metadata": {
        "id": "92968322"
      }
    },
    {
      "id": "e051f70b",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1) Setup & Installation\n",
        "\n",
        "- Upgrade `pip`\n",
        "- Install **AutoGluon** with multimodal support\n",
        "- Verify that a **GPU** is visible\n"
      ],
      "metadata": {
        "id": "e051f70b"
      }
    },
    {
      "id": "b17bf972",
      "cell_type": "code",
      "metadata": {
        "id": "b17bf972"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ðŸš€ Setup & Install\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip -q install --upgrade pip\n",
        "# Using the 'all' extra to ensure multimodal deps (vision, NLP) are installed.\n",
        "!pip -q install \"autogluon[all]\"\n",
        "!python - << 'PY'\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "PY\n",
        "\n",
        "# Check GPU (should show T4/A100/V100, etc.)\n",
        "!nvidia-smi || echo \"No GPU detected. In Colab: Runtime â†’ Change runtime type â†’ GPU\"\n"
      ],
      "outputs": []
    },
    {
      "id": "112730a0",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2) Imports\n",
        "We'll use `MultiModalPredictor` for multimodal classification and some utilities for data loading.\n"
      ],
      "metadata": {
        "id": "112730a0"
      }
    },
    {
      "id": "e6c36c45",
      "cell_type": "code",
      "metadata": {
        "id": "e6c36c45"
      },
      "execution_count": null,
      "source": [
        "\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(123)\n",
        "\n",
        "from autogluon.multimodal import MultiModalPredictor\n",
        "from autogluon.core.utils.loaders import load_zip\n"
      ],
      "outputs": []
    },
    {
      "id": "ef754c56",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3) Download & Prepare the Dataset\n",
        "\n",
        "We'll use a compact **PetFinder** tutorial dataset containing:\n",
        "- **Images** of pets\n",
        "- **Text** descriptions\n",
        "- **Tabular** features (age, breed, etc.)\n",
        "\n",
        "**Target/label:** `AdoptionSpeed` (classification).\n",
        "\n",
        "Steps:\n",
        "1. Download and unzip to a local folder\n",
        "2. Load `train.csv` and `test.csv`\n",
        "3. Normalize the image paths and keep the first image per row\n"
      ],
      "metadata": {
        "id": "ef754c56"
      }
    },
    {
      "id": "12861dfc",
      "cell_type": "code",
      "metadata": {
        "id": "12861dfc"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ðŸ“‚ Download & Prepare Dataset\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "download_dir = './ag_automm_tutorial'\n",
        "zip_url = 'https://automl-mm-bench.s3.amazonaws.com/petfinder_for_tutorial.zip'\n",
        "\n",
        "# Download + unzip using AutoGluon utility\n",
        "load_zip.unzip(zip_url, unzip_dir=download_dir)\n",
        "\n",
        "dataset_path = os.path.join(download_dir, 'petfinder_for_tutorial')\n",
        "train_csv = os.path.join(dataset_path, 'train.csv')\n",
        "test_csv  = os.path.join(dataset_path, 'test.csv')\n",
        "\n",
        "train_data = pd.read_csv(train_csv, index_col=0)\n",
        "test_data  = pd.read_csv(test_csv,  index_col=0)\n",
        "\n",
        "label_col = 'AdoptionSpeed'\n",
        "image_col = 'Images'\n",
        "\n",
        "# Keep only the first image path if multiple are present\n",
        "train_data[image_col] = train_data[image_col].astype(str).apply(lambda s: s.split(';')[0])\n",
        "test_data[image_col]  = test_data[image_col].astype(str).apply(lambda s: s.split(';')[0])\n",
        "\n",
        "# Expand relative paths to absolute paths\n",
        "def expand_paths(p, base):\n",
        "    parts = str(p).split(';')\n",
        "    return ';'.join([os.path.abspath(os.path.join(base, pp)) for pp in parts])\n",
        "\n",
        "train_data[image_col] = train_data[image_col].apply(lambda p: expand_paths(p, dataset_path))\n",
        "test_data[image_col]  = test_data[image_col].apply(lambda p: expand_paths(p, dataset_path))\n",
        "\n",
        "print(\"Train shape:\", train_data.shape)\n",
        "print(\"Test  shape:\", test_data.shape)\n",
        "print(\"Columns:\", list(train_data.columns)[:15], \"...\")\n",
        "print(\"Label column:\", label_col)\n",
        "\n",
        "# Peek at the data\n",
        "display(train_data.head(3))\n"
      ],
      "outputs": []
    },
    {
      "id": "e3965212",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4) Train a Multimodal Model\n",
        "\n",
        "We create a `MultiModalPredictor` and call `.fit(...)`.\n",
        "\n",
        "- You can adjust `time_limit` for more thorough training.\n",
        "- For quick runs in Colab, we keep it small; increase for better accuracy.\n",
        "- AutoGluon will automatically detect and use the **GPU** when available.\n"
      ],
      "metadata": {
        "id": "e3965212"
      }
    },
    {
      "id": "7aefaebd",
      "cell_type": "code",
      "metadata": {
        "id": "7aefaebd"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ðŸ§  Train MultiModalPredictor\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "save_dir = './automm_petfinder_model'\n",
        "predictor = MultiModalPredictor(label=label_col, path=save_dir)\n",
        "\n",
        "predictor.fit(\n",
        "    train_data=train_data,\n",
        "    time_limit=300,  # seconds; increase for stronger models\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "outputs": []
    },
    {
      "id": "b5be4f16",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5) Evaluate on the Test Set\n",
        "\n",
        "Use `.evaluate(test_data)` to compute metrics (e.g., accuracy, F1, etc.).\n"
      ],
      "metadata": {
        "id": "b5be4f16"
      }
    },
    {
      "id": "88bed67a",
      "cell_type": "code",
      "metadata": {
        "id": "88bed67a"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ðŸ“ˆ Evaluate\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "metrics = predictor.evaluate(test_data)\n",
        "print(\"Test metrics:\", metrics)\n"
      ],
      "outputs": []
    },
    {
      "id": "5bbb6108",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6) Generate Predictions & Probabilities\n",
        "\n",
        "Use `.predict(...)` to get class predictions and `.predict_proba(...)` for class probabilities.\n"
      ],
      "metadata": {
        "id": "5bbb6108"
      }
    },
    {
      "id": "dfa1e95c",
      "cell_type": "code",
      "metadata": {
        "id": "dfa1e95c"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ðŸ”® Predict\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "preds = predictor.predict(test_data)\n",
        "probs = predictor.predict_proba(test_data)\n",
        "\n",
        "print(\"Predictions (first 10):\")\n",
        "print(preds.head(10))\n",
        "\n",
        "print(\"\\nProbabilities (first 3 rows):\")\n",
        "display(probs.head(3))\n"
      ],
      "outputs": []
    },
    {
      "id": "36b5a3f4",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7) Save & Load the Model\n",
        "\n",
        "AutoGluon models are saved under the `path` you provided. You can reload them later and do inference without retraining.\n"
      ],
      "metadata": {
        "id": "36b5a3f4"
      }
    },
    {
      "id": "299b2b56",
      "cell_type": "code",
      "metadata": {
        "id": "299b2b56"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ðŸ’¾ Save & Reload\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"Model directory:\", predictor.path)\n",
        "\n",
        "# Reload\n",
        "reloaded = MultiModalPredictor.load(predictor.path)\n",
        "\n",
        "# Sanity-check prediction equals (or is close to) the original predictor on same data\n",
        "reloaded_preds = reloaded.predict(test_data)\n",
        "print(\"Reloaded predictions match shape:\", reloaded_preds.shape == preds.shape)\n"
      ],
      "outputs": []
    },
    {
      "id": "4bf4f60b",
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 8) (Optional) Advanced Tips & Tweaks\n",
        "\n",
        "- **Increase `time_limit`** for better results.\n",
        "- Use `hyperparameters` to control model families / backbones.\n",
        "- Try **data subsampling** for faster iteration during prototyping.\n",
        "- Use `eval_metric` to pick a specific metric aligned with your goal.\n",
        "- Explore `.fit_summary()` for training details and artifacts.\n"
      ],
      "metadata": {
        "id": "4bf4f60b"
      }
    },
    {
      "id": "3adec2d5",
      "cell_type": "code",
      "metadata": {
        "id": "3adec2d5"
      },
      "execution_count": null,
      "source": [
        "\n",
        "# Example: show a compact fit summary (if available)\n",
        "try:\n",
        "    summary = predictor.fit_summary()\n",
        "    if isinstance(summary, dict):\n",
        "        print(\"fit_summary keys:\", list(summary.keys()))\n",
        "    else:\n",
        "        print(summary)\n",
        "except Exception as e:\n",
        "    print(\"fit_summary not available or failed:\", e)\n"
      ],
      "outputs": []
    },
    {
      "id": "aa3c605a",
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### âœ… Youâ€™re Done!\n",
        "You trained, evaluated, predicted, and saved a **multimodal** model with images, text, and tabular features using **AutoGluon**.\n",
        "\n",
        "**Next ideas:**\n",
        "- Swap in your own dataset with similar columns (image paths + text + tabular + label).\n",
        "- Tune hyperparameters and increase training time for higher accuracy.\n",
        "- Export embeddings with `predictor.extract_embedding(...)` for downstream tasks.\n"
      ],
      "metadata": {
        "id": "aa3c605a"
      }
    }
  ]
}